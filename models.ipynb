{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers\n",
        "from sklearn.model_selection import train_test_split\n"
      ],
      "metadata": {
        "id": "647uBX1Is96c"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "id": "FYH6GbbkU0Il"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import matplotlib as pl\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "(f_train, f_test), f_info = tfds.load('fashion_mnist', split=['train','test'],  with_info=True, as_supervised=True)\n",
        "(d_train, d_test), d_info = tfds.load('mnist', split=['train', 'test'], with_info=True, as_supervised=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "id": "7u-R9Wq8VpEq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5110a8db-7126-4ed3-f176-34065f5eb60a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  0],\n",
              "       [  0],\n",
              "       [  0],\n",
              "       [  0],\n",
              "       [  0],\n",
              "       [  0],\n",
              "       [  0],\n",
              "       [  0],\n",
              "       [  0],\n",
              "       [ 18],\n",
              "       [ 77],\n",
              "       [227],\n",
              "       [227],\n",
              "       [208],\n",
              "       [210],\n",
              "       [225],\n",
              "       [216],\n",
              "       [ 85],\n",
              "       [ 32],\n",
              "       [  0],\n",
              "       [  0],\n",
              "       [  0],\n",
              "       [  0],\n",
              "       [  0],\n",
              "       [  0],\n",
              "       [  0],\n",
              "       [  0],\n",
              "       [  0]], dtype=uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ],
      "source": [
        "some_examples = tfds.as_dataframe(f_train.take(5), f_info)\n",
        "some_examples.iloc[0].image[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "FMNIST and MNIST both present images as 28 x 28 x 1 np arrays of integers in [0, 255]. Because Keras can directly handle datasets, we don't necessarily need to process them further to feed into a CNN, and indeed that would be smart if the datasets were too large to fit in memory. On the other hand, for this little project, I want to indicate what's happening inside the datasets, so I'll extract to a dataframe and process that."
      ],
      "metadata": {
        "id": "tzqSF7FFfe_Y"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F2buxXXtfiuO",
        "outputId": "3f665668-bee6-4247-dd58-2af71580fd87"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensorflow.python.data.ops.dataset_ops.PrefetchDataset"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ],
      "source": [
        "type(f_train)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "f_train_df = tfds.as_dataframe(f_train, f_info)\n",
        "f_test_df = tfds.as_dataframe(f_test, f_info)\n",
        "d_train_df = tfds.as_dataframe(d_train, d_info)\n",
        "d_test_df = tfds.as_dataframe(d_test, d_info)"
      ],
      "metadata": {
        "id": "IfFttmuDh9Uc"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f_train_df.iloc[0], f_train_df.dtypes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M7TGga-Pj07a",
        "outputId": "bc98659f-daad-42c4-bdec-a6ec427ab0f0"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "image    [[[0], [0], [0], [0], [0], [0], [0], [0], [0],...\n",
            "label                                                    2\n",
            "Name: 0, dtype: object image    object\n",
            "label     int64\n",
            "dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "f_train_df has an image column consisting of a 28 x 28 x 1 np array of np uint8, and a np int64 label (0 to 9) "
      ],
      "metadata": {
        "id": "_jUILdJrj7U4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "type(f_train_df.image.iloc[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "my07mFMwklon",
        "outputId": "00e4bf03-1065-425b-b6ea-7e9c749f404a"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "f_train_df.head()"
      ],
      "metadata": {
        "id": "Rz8hrXk3lHRA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "ac026475-7036-44cc-aab6-88c7e1e14293"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                               image  label\n",
              "0  [[[0], [0], [0], [0], [0], [0], [0], [0], [0],...      2\n",
              "1  [[[0], [0], [0], [0], [0], [0], [0], [0], [0],...      1\n",
              "2  [[[0], [0], [0], [0], [0], [0], [0], [0], [0],...      8\n",
              "3  [[[0], [0], [0], [0], [0], [0], [0], [0], [0],...      4\n",
              "4  [[[0], [0], [0], [0], [0], [0], [0], [0], [0],...      1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a01cab78-8101-49ec-bb66-8b6bce4edcac\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[[[0], [0], [0], [0], [0], [0], [0], [0], [0],...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[[[0], [0], [0], [0], [0], [0], [0], [0], [0],...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[[[0], [0], [0], [0], [0], [0], [0], [0], [0],...</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[[[0], [0], [0], [0], [0], [0], [0], [0], [0],...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[[[0], [0], [0], [0], [0], [0], [0], [0], [0],...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a01cab78-8101-49ec-bb66-8b6bce4edcac')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a01cab78-8101-49ec-bb66-8b6bce4edcac button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a01cab78-8101-49ec-bb66-8b6bce4edcac');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's start with a naive neural network approach: going straight from input to output with a single dense layer. "
      ],
      "metadata": {
        "id": "vIfhAu19lIM3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_trainval_f = np.stack(f_train_df.image.to_numpy())\n",
        "X_test_f = np.stack(f_test_df.image.to_numpy())\n",
        "X_trainval_d = np.stack(d_train_df.image.to_numpy())\n",
        "X_test_d = np.stack(d_test_df.image.to_numpy())"
      ],
      "metadata": {
        "id": "Skz38HS_mXnc"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_trainval_f = f_train_df.label.to_numpy()\n",
        "y_test_f = f_test_df.label.to_numpy()\n",
        "y_trainval_d = d_train_df.label.to_numpy()\n",
        "y_test_d = d_test_df.label.to_numpy()"
      ],
      "metadata": {
        "id": "ILY7jBjN3TA-"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_f, X_val_f, y_train_f, y_val_f = train_test_split(X_trainval_f, y_trainval_f, test_size=.2, random_state=926)\n",
        "X_train_d, X_val_d, y_train_d, y_val_d = train_test_split(X_trainval_d, y_trainval_d, test_size=.2, random_state=926)"
      ],
      "metadata": {
        "id": "hGHcFZ0n3dGT"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = tf.keras.Input(shape=(28, 28, 1))"
      ],
      "metadata": {
        "id": "IUPRkT3QsYaf"
      },
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model0 = tf.keras.Sequential([\n",
        "    layers.InputLayer(input_shape=(28,28,1)),\n",
        "    layers.Rescaling(1.0/255),\n",
        "    layers.Flatten(input_shape=(28,28,1)),\n",
        "    layers.Dense(10)\n",
        "])"
      ],
      "metadata": {
        "id": "AR1aAYU2smWH"
      },
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model0.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fg8LuGvMvjYj",
        "outputId": "1b09155d-8f9d-491b-e913-64498ee293c2"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_12\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " rescaling_20 (Rescaling)    (None, 28, 28, 1)         0         \n",
            "                                                                 \n",
            " flatten_18 (Flatten)        (None, 784)               0         \n",
            "                                                                 \n",
            " dense_32 (Dense)            (None, 10)                7850      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 7,850\n",
            "Trainable params: 7,850\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following compile statement will be unchanged for all models I run today, unless there's serious evidence a model is failing to converge. Adam is a little opaque algorithm-wise, but its performance is state-of-the-art according to the literature."
      ],
      "metadata": {
        "id": "0nN0IDZwr4Gz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model0.compile(optimizer=tf.keras.optimizers.Adam(0.001),\n",
        "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])"
      ],
      "metadata": {
        "id": "jRXKVHVsvrVq"
      },
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history0 = model0.fit(X_train_f, y_train_f, epochs=6, validation_data=(X_val_f, y_val_f))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7kr04s-7282y",
        "outputId": "3a32cb28-15a0-4579-9821-b4e3e81b178d"
      },
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/6\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.6252 - sparse_categorical_accuracy: 0.7867 - val_loss: 0.5036 - val_sparse_categorical_accuracy: 0.8234\n",
            "Epoch 2/6\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.4746 - sparse_categorical_accuracy: 0.8368 - val_loss: 0.4528 - val_sparse_categorical_accuracy: 0.8469\n",
            "Epoch 3/6\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 0.4454 - sparse_categorical_accuracy: 0.8469 - val_loss: 0.4334 - val_sparse_categorical_accuracy: 0.8528\n",
            "Epoch 4/6\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.4286 - sparse_categorical_accuracy: 0.8531 - val_loss: 0.4320 - val_sparse_categorical_accuracy: 0.8507\n",
            "Epoch 5/6\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.4190 - sparse_categorical_accuracy: 0.8542 - val_loss: 0.4176 - val_sparse_categorical_accuracy: 0.8567\n",
            "Epoch 6/6\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.4126 - sparse_categorical_accuracy: 0.8568 - val_loss: 0.4128 - val_sparse_categorical_accuracy: 0.8602\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "I am fairly astonished that this neural network handles so much of fmnist accurately"
      ],
      "metadata": {
        "id": "D8J6DzBE-thJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model0.evaluate(X_test_f, y_test_f)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C1ZaxXnP_hbQ",
        "outputId": "687b559f-9659-4443-9038-a3b47d0e62f2"
      },
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 1ms/step - loss: 0.4483 - sparse_categorical_accuracy: 0.8440\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.44826844334602356, 0.843999981880188]"
            ]
          },
          "metadata": {},
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The test accuracy is 84.4%, without any deep learning! MNIST will presumably be similar "
      ],
      "metadata": {
        "id": "RuWCC989_qA7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "d_model0 = tf.keras.Sequential([\n",
        "    layers.InputLayer(input_shape=(28,28,1)),\n",
        "    layers.Rescaling(1.0/255),\n",
        "    layers.Flatten(input_shape=(28,28,1)),\n",
        "    layers.Dense(10)\n",
        "])\n",
        "d_model0.compile(optimizer=tf.keras.optimizers.Adam(0.001),\n",
        "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])\n",
        "d_history0 = d_model0.fit(X_train_d, y_train_d, epochs=6, validation_data=(X_val_d, y_val_d))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SevLfrpV_5KZ",
        "outputId": "8822f2f3-9e5b-4384-81cb-ffcf03de9c8d"
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/6\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.5095 - sparse_categorical_accuracy: 0.8682 - val_loss: 0.3372 - val_sparse_categorical_accuracy: 0.9095\n",
            "Epoch 2/6\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.3138 - sparse_categorical_accuracy: 0.9121 - val_loss: 0.3055 - val_sparse_categorical_accuracy: 0.9158\n",
            "Epoch 3/6\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.2887 - sparse_categorical_accuracy: 0.9190 - val_loss: 0.2936 - val_sparse_categorical_accuracy: 0.9182\n",
            "Epoch 4/6\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.2762 - sparse_categorical_accuracy: 0.9221 - val_loss: 0.2909 - val_sparse_categorical_accuracy: 0.9213\n",
            "Epoch 5/6\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.2687 - sparse_categorical_accuracy: 0.9253 - val_loss: 0.2863 - val_sparse_categorical_accuracy: 0.9203\n",
            "Epoch 6/6\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.2630 - sparse_categorical_accuracy: 0.9268 - val_loss: 0.2825 - val_sparse_categorical_accuracy: 0.9214\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "d_model0.evaluate(X_test_d, y_test_d)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EwQ6aOm3BCsp",
        "outputId": "9f9ebbee-bb5d-481a-ec1e-ffcab4da5c67"
      },
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 1ms/step - loss: 0.2682 - sparse_categorical_accuracy: 0.9249\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.26818469166755676, 0.9248999953269958]"
            ]
          },
          "metadata": {},
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "92.1% validation accuracy, 92.5% test accuracy. MNIST is well-known for producing these high accuracy results. But can these be improved?\n",
        "\n",
        "We'll start by adding some depth to the first neural network."
      ],
      "metadata": {
        "id": "q8lFNuMYA85B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3,\n",
        "                                            verbose=1)\n",
        "# This was added in response to early tests revealing under-training,\n",
        "# see below."
      ],
      "metadata": {
        "id": "-kOlkN8ADvuG"
      },
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model1 = tf.keras.Sequential([\n",
        "    layers.InputLayer(input_shape=(28,28,1)),\n",
        "    layers.Rescaling(1.0/255),\n",
        "    layers.Flatten(input_shape=(28,28,1)),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(10)\n",
        "])"
      ],
      "metadata": {
        "id": "HWfdBTyVBsH8"
      },
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model2 = tf.keras.Sequential([\n",
        "    layers.InputLayer(input_shape=(28,28,1)),\n",
        "    layers.Rescaling(1.0/255),\n",
        "    layers.Flatten(input_shape=(28,28,1)),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(32, activation='relu'),\n",
        "    layers.Dense(10)\n",
        "])\n"
      ],
      "metadata": {
        "id": "Duti0O45Bzd_"
      },
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model1.compile(optimizer=tf.keras.optimizers.Adam(0.001),\n",
        "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])\n",
        "model2.compile(optimizer=tf.keras.optimizers.Adam(0.001),\n",
        "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])"
      ],
      "metadata": {
        "id": "yuz0sk10CRf2"
      },
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history1 = model1.fit(X_train_f, y_train_f, epochs=20, \n",
        "                      validation_data=(X_val_f, y_val_f), callbacks=[callback])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rlSRKDbOCWYX",
        "outputId": "01fb8f41-000e-4fdb-eed4-b3c3de1a75f6"
      },
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.5500 - sparse_categorical_accuracy: 0.8103 - val_loss: 0.4318 - val_sparse_categorical_accuracy: 0.8497\n",
            "Epoch 2/20\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.4069 - sparse_categorical_accuracy: 0.8560 - val_loss: 0.3940 - val_sparse_categorical_accuracy: 0.8630\n",
            "Epoch 3/20\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 0.3678 - sparse_categorical_accuracy: 0.8681 - val_loss: 0.3638 - val_sparse_categorical_accuracy: 0.8694\n",
            "Epoch 4/20\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.3452 - sparse_categorical_accuracy: 0.8749 - val_loss: 0.3762 - val_sparse_categorical_accuracy: 0.8583\n",
            "Epoch 5/20\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.3265 - sparse_categorical_accuracy: 0.8804 - val_loss: 0.3282 - val_sparse_categorical_accuracy: 0.8832\n",
            "Epoch 6/20\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.3088 - sparse_categorical_accuracy: 0.8866 - val_loss: 0.3277 - val_sparse_categorical_accuracy: 0.8835\n",
            "Epoch 7/20\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.2979 - sparse_categorical_accuracy: 0.8910 - val_loss: 0.3228 - val_sparse_categorical_accuracy: 0.8835\n",
            "Epoch 8/20\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.2868 - sparse_categorical_accuracy: 0.8941 - val_loss: 0.3200 - val_sparse_categorical_accuracy: 0.8837\n",
            "Epoch 9/20\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 0.2806 - sparse_categorical_accuracy: 0.8964 - val_loss: 0.3340 - val_sparse_categorical_accuracy: 0.8817\n",
            "Epoch 10/20\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 0.2711 - sparse_categorical_accuracy: 0.8998 - val_loss: 0.3268 - val_sparse_categorical_accuracy: 0.8820\n",
            "Epoch 11/20\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.2633 - sparse_categorical_accuracy: 0.9025 - val_loss: 0.3216 - val_sparse_categorical_accuracy: 0.8861\n",
            "Epoch 11: early stopping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history2 = model2.fit(X_train_f, y_train_f, epochs=20,\n",
        "                      validation_data=(X_val_f, y_val_f), callbacks=[callback])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8SG05hSrChpd",
        "outputId": "13f4e3cd-6743-4b75-b3cf-4cba5c9e3263"
      },
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.5445 - sparse_categorical_accuracy: 0.8082 - val_loss: 0.4822 - val_sparse_categorical_accuracy: 0.8267\n",
            "Epoch 2/20\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.3999 - sparse_categorical_accuracy: 0.8572 - val_loss: 0.3756 - val_sparse_categorical_accuracy: 0.8644\n",
            "Epoch 3/20\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.3660 - sparse_categorical_accuracy: 0.8679 - val_loss: 0.3561 - val_sparse_categorical_accuracy: 0.8717\n",
            "Epoch 4/20\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 0.3407 - sparse_categorical_accuracy: 0.8761 - val_loss: 0.3426 - val_sparse_categorical_accuracy: 0.8740\n",
            "Epoch 5/20\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 0.3241 - sparse_categorical_accuracy: 0.8808 - val_loss: 0.3526 - val_sparse_categorical_accuracy: 0.8729\n",
            "Epoch 6/20\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.3089 - sparse_categorical_accuracy: 0.8862 - val_loss: 0.3271 - val_sparse_categorical_accuracy: 0.8840\n",
            "Epoch 7/20\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 0.2954 - sparse_categorical_accuracy: 0.8915 - val_loss: 0.3371 - val_sparse_categorical_accuracy: 0.8776\n",
            "Epoch 8/20\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 0.2838 - sparse_categorical_accuracy: 0.8933 - val_loss: 0.3372 - val_sparse_categorical_accuracy: 0.8798\n",
            "Epoch 9/20\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 0.2717 - sparse_categorical_accuracy: 0.8986 - val_loss: 0.3193 - val_sparse_categorical_accuracy: 0.8841\n",
            "Epoch 10/20\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 0.2676 - sparse_categorical_accuracy: 0.8996 - val_loss: 0.3440 - val_sparse_categorical_accuracy: 0.8736\n",
            "Epoch 11/20\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.2604 - sparse_categorical_accuracy: 0.9029 - val_loss: 0.3199 - val_sparse_categorical_accuracy: 0.8867\n",
            "Epoch 12/20\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 0.2495 - sparse_categorical_accuracy: 0.9058 - val_loss: 0.3117 - val_sparse_categorical_accuracy: 0.8907\n",
            "Epoch 13/20\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 0.2461 - sparse_categorical_accuracy: 0.9089 - val_loss: 0.3090 - val_sparse_categorical_accuracy: 0.8903\n",
            "Epoch 14/20\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.2392 - sparse_categorical_accuracy: 0.9115 - val_loss: 0.3100 - val_sparse_categorical_accuracy: 0.8924\n",
            "Epoch 15/20\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.2347 - sparse_categorical_accuracy: 0.9117 - val_loss: 0.3084 - val_sparse_categorical_accuracy: 0.8948\n",
            "Epoch 16/20\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.2247 - sparse_categorical_accuracy: 0.9159 - val_loss: 0.3216 - val_sparse_categorical_accuracy: 0.8900\n",
            "Epoch 17/20\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.2241 - sparse_categorical_accuracy: 0.9170 - val_loss: 0.3187 - val_sparse_categorical_accuracy: 0.8914\n",
            "Epoch 18/20\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.2175 - sparse_categorical_accuracy: 0.9181 - val_loss: 0.3332 - val_sparse_categorical_accuracy: 0.8886\n",
            "Epoch 18: early stopping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The first few runs here, I kept incrasing epoch count because the validation error kept going down. But then overtraining set in, and it is worthwhile to stop training at that point. So I put in a callback above, and ran both models until the val_loss stopped going down. The larger model performed only slightly better than the smaller one.\n",
        "\n",
        "Both models perform better on the validation set than model0, so there's some value to deep learning!\n",
        "I will refrain from running them against the test set until the very end, because I may want to fiddle with hyperparameters some more.\n",
        "\n",
        "For instance, let's fiddle with model2 by adding in more nodes in the dense layers."
      ],
      "metadata": {
        "id": "_yHbCMtcDdX4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "metadata": {
        "id": "d8xc-PNoeiQr"
      },
      "outputs": [],
      "source": [
        "model3 = tf.keras.Sequential([\n",
        "    layers.InputLayer(input_shape=(28,28,1)),\n",
        "    layers.Rescaling(1.0/255),\n",
        "    layers.Flatten(input_shape=(28,28,1)),\n",
        "    layers.Dense(256, activation='relu'),\n",
        "    layers.Dense(128, activation='relu'),\n",
        "    layers.Dense(10)\n",
        "])\n",
        "model3.compile(optimizer=tf.keras.optimizers.Adam(0.001),\n",
        "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history3 = model3.fit(X_train_f, y_train_f, epochs=20,\n",
        "                      validation_data=(X_val_f, y_val_f), callbacks=[callback])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IBGvSIQ5F75_",
        "outputId": "4c89dcdb-62e8-4e3b-f002-c0864ebb70f9"
      },
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.4959 - sparse_categorical_accuracy: 0.8219 - val_loss: 0.4011 - val_sparse_categorical_accuracy: 0.8600\n",
            "Epoch 2/20\n",
            "1500/1500 [==============================] - 5s 4ms/step - loss: 0.3702 - sparse_categorical_accuracy: 0.8643 - val_loss: 0.3571 - val_sparse_categorical_accuracy: 0.8704\n",
            "Epoch 3/20\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.3347 - sparse_categorical_accuracy: 0.8753 - val_loss: 0.3376 - val_sparse_categorical_accuracy: 0.8762\n",
            "Epoch 4/20\n",
            "1500/1500 [==============================] - 4s 2ms/step - loss: 0.3106 - sparse_categorical_accuracy: 0.8847 - val_loss: 0.3208 - val_sparse_categorical_accuracy: 0.8813\n",
            "Epoch 5/20\n",
            "1500/1500 [==============================] - 4s 2ms/step - loss: 0.2913 - sparse_categorical_accuracy: 0.8911 - val_loss: 0.3453 - val_sparse_categorical_accuracy: 0.8740\n",
            "Epoch 6/20\n",
            "1500/1500 [==============================] - 4s 2ms/step - loss: 0.2764 - sparse_categorical_accuracy: 0.8956 - val_loss: 0.2928 - val_sparse_categorical_accuracy: 0.8949\n",
            "Epoch 7/20\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2635 - sparse_categorical_accuracy: 0.9001 - val_loss: 0.2994 - val_sparse_categorical_accuracy: 0.8928\n",
            "Epoch 8/20\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2515 - sparse_categorical_accuracy: 0.9046 - val_loss: 0.3060 - val_sparse_categorical_accuracy: 0.8903\n",
            "Epoch 9/20\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2410 - sparse_categorical_accuracy: 0.9105 - val_loss: 0.2873 - val_sparse_categorical_accuracy: 0.8949\n",
            "Epoch 10/20\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2307 - sparse_categorical_accuracy: 0.9117 - val_loss: 0.2901 - val_sparse_categorical_accuracy: 0.8965\n",
            "Epoch 11/20\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2239 - sparse_categorical_accuracy: 0.9146 - val_loss: 0.2912 - val_sparse_categorical_accuracy: 0.8951\n",
            "Epoch 12/20\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2147 - sparse_categorical_accuracy: 0.9166 - val_loss: 0.3059 - val_sparse_categorical_accuracy: 0.8946\n",
            "Epoch 12: early stopping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The most minor of improvements! Let's compare to what we can do with a CNN."
      ],
      "metadata": {
        "id": "xzxRdNuNH3Y5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model4 = tf.keras.Sequential([\n",
        "    layers.InputLayer(input_shape=(28,28,1)),\n",
        "    layers.Rescaling(1.0/255),\n",
        "    layers.Conv2D(64, kernel_size=(3,3), activation='relu', input_shape=(28,28,1)),\n",
        "    layers.MaxPooling2D(pool_size=(2,2)),\n",
        "    layers.Flatten(),\n",
        "    layers.Flatten(input_shape=(28,28,1)),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(10)\n",
        "])\n",
        "\n"
      ],
      "metadata": {
        "id": "_5PDJAHEBrry"
      },
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model4.compile(optimizer=tf.keras.optimizers.Adam(0.001),\n",
        "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])"
      ],
      "metadata": {
        "id": "cmbHJKXyPkA4"
      },
      "execution_count": 123,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history4 = model4.fit(X_train_f, y_train_f, epochs=20,\n",
        "                      validation_data=(X_val_f, y_val_f), callbacks=[callback])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kgRKuM_DPqYp",
        "outputId": "9d630a12-1cb6-4783-f163-ca8d92a77ec1"
      },
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "1500/1500 [==============================] - 34s 22ms/step - loss: 0.4174 - sparse_categorical_accuracy: 0.8512 - val_loss: 0.3086 - val_sparse_categorical_accuracy: 0.8896\n",
            "Epoch 2/20\n",
            "1500/1500 [==============================] - 31s 21ms/step - loss: 0.2790 - sparse_categorical_accuracy: 0.8987 - val_loss: 0.2649 - val_sparse_categorical_accuracy: 0.9061\n",
            "Epoch 3/20\n",
            "1500/1500 [==============================] - 30s 20ms/step - loss: 0.2330 - sparse_categorical_accuracy: 0.9152 - val_loss: 0.2480 - val_sparse_categorical_accuracy: 0.9138\n",
            "Epoch 4/20\n",
            "1500/1500 [==============================] - 27s 18ms/step - loss: 0.1996 - sparse_categorical_accuracy: 0.9269 - val_loss: 0.2444 - val_sparse_categorical_accuracy: 0.9143\n",
            "Epoch 5/20\n",
            "1500/1500 [==============================] - 26s 17ms/step - loss: 0.1738 - sparse_categorical_accuracy: 0.9358 - val_loss: 0.2426 - val_sparse_categorical_accuracy: 0.9143\n",
            "Epoch 6/20\n",
            "1500/1500 [==============================] - 26s 17ms/step - loss: 0.1494 - sparse_categorical_accuracy: 0.9446 - val_loss: 0.2357 - val_sparse_categorical_accuracy: 0.9208\n",
            "Epoch 7/20\n",
            "1500/1500 [==============================] - 27s 18ms/step - loss: 0.1291 - sparse_categorical_accuracy: 0.9532 - val_loss: 0.2420 - val_sparse_categorical_accuracy: 0.9221\n",
            "Epoch 8/20\n",
            "1500/1500 [==============================] - 26s 17ms/step - loss: 0.1111 - sparse_categorical_accuracy: 0.9596 - val_loss: 0.2732 - val_sparse_categorical_accuracy: 0.9170\n",
            "Epoch 9/20\n",
            "1500/1500 [==============================] - 25s 17ms/step - loss: 0.0922 - sparse_categorical_accuracy: 0.9666 - val_loss: 0.2701 - val_sparse_categorical_accuracy: 0.9190\n",
            "Epoch 9: early stopping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This basic CNN improves validation accuracy to 91.9%, but is seriously overtraining. What if we add a layer and some dropout?"
      ],
      "metadata": {
        "id": "_2ZVbVvNRFpi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model5 = tf.keras.models.Sequential([\n",
        "    layers.InputLayer(input_shape=(28,28,1)),\n",
        "    layers.Rescaling(1.0/255),\n",
        "    layers.Conv2D(32, kernel_size=(3,3), activation='relu'),\n",
        "    layers.MaxPooling2D(pool_size=(2,2)),\n",
        "    layers.Conv2D(64, kernel_size=(3,3), activation='relu'),\n",
        "    layers.MaxPooling2D(pool_size=(2,2)),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(128, activation='relu'),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Dense(10)\n",
        "])\n"
      ],
      "metadata": {
        "id": "upP25IFRb3d3"
      },
      "execution_count": 126,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model5.compile(optimizer=tf.keras.optimizers.Adam(0.001),\n",
        "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])"
      ],
      "metadata": {
        "id": "XS4OUVpdU1HN"
      },
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history5 = model5.fit(X_train_f, y_train_f, epochs=20,\n",
        "                      validation_data=(X_val_f, y_val_f), callbacks=[callback])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nmbN3p8iU7hV",
        "outputId": "4f29fef6-5170-430f-8645-49350e258b6e"
      },
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "1500/1500 [==============================] - 32s 21ms/step - loss: 0.6050 - sparse_categorical_accuracy: 0.7801 - val_loss: 0.3582 - val_sparse_categorical_accuracy: 0.8701\n",
            "Epoch 2/20\n",
            "1500/1500 [==============================] - 31s 21ms/step - loss: 0.4007 - sparse_categorical_accuracy: 0.8557 - val_loss: 0.3152 - val_sparse_categorical_accuracy: 0.8822\n",
            "Epoch 3/20\n",
            "1500/1500 [==============================] - 30s 20ms/step - loss: 0.3499 - sparse_categorical_accuracy: 0.8717 - val_loss: 0.2901 - val_sparse_categorical_accuracy: 0.8934\n",
            "Epoch 4/20\n",
            "1500/1500 [==============================] - 31s 20ms/step - loss: 0.3188 - sparse_categorical_accuracy: 0.8846 - val_loss: 0.2777 - val_sparse_categorical_accuracy: 0.8937\n",
            "Epoch 5/20\n",
            "1500/1500 [==============================] - 31s 21ms/step - loss: 0.2942 - sparse_categorical_accuracy: 0.8920 - val_loss: 0.2687 - val_sparse_categorical_accuracy: 0.8989\n",
            "Epoch 6/20\n",
            "1500/1500 [==============================] - 30s 20ms/step - loss: 0.2739 - sparse_categorical_accuracy: 0.8992 - val_loss: 0.2513 - val_sparse_categorical_accuracy: 0.9088\n",
            "Epoch 7/20\n",
            "1500/1500 [==============================] - 30s 20ms/step - loss: 0.2552 - sparse_categorical_accuracy: 0.9061 - val_loss: 0.2353 - val_sparse_categorical_accuracy: 0.9115\n",
            "Epoch 8/20\n",
            "1500/1500 [==============================] - 30s 20ms/step - loss: 0.2425 - sparse_categorical_accuracy: 0.9103 - val_loss: 0.2401 - val_sparse_categorical_accuracy: 0.9118\n",
            "Epoch 9/20\n",
            "1500/1500 [==============================] - 30s 20ms/step - loss: 0.2289 - sparse_categorical_accuracy: 0.9147 - val_loss: 0.2344 - val_sparse_categorical_accuracy: 0.9163\n",
            "Epoch 10/20\n",
            "1500/1500 [==============================] - 31s 21ms/step - loss: 0.2146 - sparse_categorical_accuracy: 0.9216 - val_loss: 0.2408 - val_sparse_categorical_accuracy: 0.9146\n",
            "Epoch 11/20\n",
            "1500/1500 [==============================] - 31s 21ms/step - loss: 0.2053 - sparse_categorical_accuracy: 0.9230 - val_loss: 0.2486 - val_sparse_categorical_accuracy: 0.9158\n",
            "Epoch 12/20\n",
            "1500/1500 [==============================] - 30s 20ms/step - loss: 0.1940 - sparse_categorical_accuracy: 0.9276 - val_loss: 0.2385 - val_sparse_categorical_accuracy: 0.9147\n",
            "Epoch 12: early stopping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This was slow and ultimately ineffective, with a little overtraining for good measure. We will need to implement another CNN to get sustainably >90% validation accuracy. Let's try batch normalization, as recommended by \"An Ensemble of Simple Convolutional Neural Network Models for MNIST Digit Recognition\"."
      ],
      "metadata": {
        "id": "lHC7LkYdE2zD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 129,
      "metadata": {
        "id": "eavmMBwZfhbs"
      },
      "outputs": [],
      "source": [
        "model6 = tf.keras.Sequential([\n",
        "    layers.InputLayer(input_shape=(28,28,1)),\n",
        "    layers.Rescaling(1.0/255),\n",
        "    layers.Conv2D(64, kernel_size=(5,5), padding='same', activation='relu'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.MaxPool2D(pool_size=(2,2)),\n",
        "    layers.Conv2D(128, kernel_size=(5,5), padding='same', activation='relu'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.MaxPool2D(pool_size=(2,2)),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(10)\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model6.compile(optimizer=tf.keras.optimizers.Adam(0.001),\n",
        "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])"
      ],
      "metadata": {
        "id": "Ech3qJ0RImP5"
      },
      "execution_count": 130,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model6.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wy7tR3i8QUew",
        "outputId": "3d3ad4e4-b8d5-4e47-ad02-46606e1c3f3d"
      },
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_21\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " rescaling_29 (Rescaling)    (None, 28, 28, 1)         0         \n",
            "                                                                 \n",
            " conv2d_39 (Conv2D)          (None, 28, 28, 64)        1664      \n",
            "                                                                 \n",
            " batch_normalization_23 (Bat  (None, 28, 28, 64)       256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling2d_21 (MaxPoolin  (None, 14, 14, 64)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_40 (Conv2D)          (None, 14, 14, 128)       204928    \n",
            "                                                                 \n",
            " batch_normalization_24 (Bat  (None, 14, 14, 128)      512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling2d_22 (MaxPoolin  (None, 7, 7, 128)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_29 (Flatten)        (None, 6272)              0         \n",
            "                                                                 \n",
            " dense_50 (Dense)            (None, 10)                62730     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 270,090\n",
            "Trainable params: 269,706\n",
            "Non-trainable params: 384\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history6 = model6.fit(X_train_f, y_train_f, epochs=20,\n",
        "                      validation_data=(X_val_f, y_val_f), callbacks=[callback])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C9ilnF-kIqV1",
        "outputId": "b958dda6-b6e7-4861-9419-42087de387e3"
      },
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "1500/1500 [==============================] - 240s 159ms/step - loss: 0.6178 - sparse_categorical_accuracy: 0.8323 - val_loss: 0.4381 - val_sparse_categorical_accuracy: 0.8693\n",
            "Epoch 2/20\n",
            "1500/1500 [==============================] - 236s 157ms/step - loss: 0.3660 - sparse_categorical_accuracy: 0.8860 - val_loss: 0.3052 - val_sparse_categorical_accuracy: 0.9049\n",
            "Epoch 3/20\n",
            "1500/1500 [==============================] - 237s 158ms/step - loss: 0.2755 - sparse_categorical_accuracy: 0.9069 - val_loss: 0.2588 - val_sparse_categorical_accuracy: 0.9082\n",
            "Epoch 4/20\n",
            "1500/1500 [==============================] - 235s 156ms/step - loss: 0.2295 - sparse_categorical_accuracy: 0.9184 - val_loss: 0.3052 - val_sparse_categorical_accuracy: 0.8929\n",
            "Epoch 5/20\n",
            "1500/1500 [==============================] - 237s 158ms/step - loss: 0.1938 - sparse_categorical_accuracy: 0.9299 - val_loss: 0.2410 - val_sparse_categorical_accuracy: 0.9194\n",
            "Epoch 6/20\n",
            "1500/1500 [==============================] - 234s 156ms/step - loss: 0.1756 - sparse_categorical_accuracy: 0.9365 - val_loss: 0.2437 - val_sparse_categorical_accuracy: 0.9148\n",
            "Epoch 7/20\n",
            "1500/1500 [==============================] - 235s 156ms/step - loss: 0.1513 - sparse_categorical_accuracy: 0.9459 - val_loss: 0.2364 - val_sparse_categorical_accuracy: 0.9217\n",
            "Epoch 8/20\n",
            "1500/1500 [==============================] - 234s 156ms/step - loss: 0.1312 - sparse_categorical_accuracy: 0.9531 - val_loss: 0.2766 - val_sparse_categorical_accuracy: 0.9064\n",
            "Epoch 9/20\n",
            "1500/1500 [==============================] - 235s 157ms/step - loss: 0.1124 - sparse_categorical_accuracy: 0.9595 - val_loss: 0.3017 - val_sparse_categorical_accuracy: 0.9043\n",
            "Epoch 10/20\n",
            "1500/1500 [==============================] - 234s 156ms/step - loss: 0.1003 - sparse_categorical_accuracy: 0.9634 - val_loss: 0.4879 - val_sparse_categorical_accuracy: 0.8829\n",
            "Epoch 10: early stopping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "These results are pretty mediocre, especially given the amount of compute involved. After Epoch 7, the validation loss as pretty good, but then the model started seriously overtraining.\n",
        "\n",
        "To end, let's simply add some padding to Model 5; hopefully that improves performance to something decent.\n",
        "\n"
      ],
      "metadata": {
        "id": "Qtt-01ZdKy3V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model7 = tf.keras.Sequential([\n",
        "    layers.InputLayer(input_shape=(28,28,1)),\n",
        "    layers.Rescaling(1.0/255),\n",
        "    layers.Conv2D(32, kernel_size=(3,3), input_shape=(28,28,1), padding='same', activation='relu'),\n",
        "    layers.MaxPool2D(pool_size=(2,2)),\n",
        "    layers.Conv2D(64, kernel_size=(3,3), padding='same', activation='relu'),\n",
        "    layers.MaxPool2D(pool_size=(2,2)),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(128, activation='relu'),\n",
        "    layers.Dropout(0.6),\n",
        "    layers.Dense(10)\n",
        "])\n",
        "model7.compile(optimizer=tf.keras.optimizers.Adam(0.001),\n",
        "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])\n",
        "model7.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VZU60gzjYiva",
        "outputId": "62c0246b-bda8-4501-e92e-21d3891b05df"
      },
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_22\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " rescaling_30 (Rescaling)    (None, 28, 28, 1)         0         \n",
            "                                                                 \n",
            " conv2d_41 (Conv2D)          (None, 28, 28, 32)        320       \n",
            "                                                                 \n",
            " max_pooling2d_23 (MaxPoolin  (None, 14, 14, 32)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_42 (Conv2D)          (None, 14, 14, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_24 (MaxPoolin  (None, 7, 7, 64)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_30 (Flatten)        (None, 3136)              0         \n",
            "                                                                 \n",
            " dense_51 (Dense)            (None, 128)               401536    \n",
            "                                                                 \n",
            " dropout_7 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_52 (Dense)            (None, 10)                1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 421,642\n",
            "Trainable params: 421,642\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history7 = model7.fit(X_train_f, y_train_f, epochs=20,\n",
        "                      validation_data=(X_val_f, y_val_f), callbacks=[callback])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TZIgOUzBY6TN",
        "outputId": "4b9663a3-c50f-443f-dcee-224f57d3f633"
      },
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "1500/1500 [==============================] - 42s 28ms/step - loss: 0.5982 - sparse_categorical_accuracy: 0.7860 - val_loss: 0.3583 - val_sparse_categorical_accuracy: 0.8682\n",
            "Epoch 2/20\n",
            "1500/1500 [==============================] - 42s 28ms/step - loss: 0.4045 - sparse_categorical_accuracy: 0.8567 - val_loss: 0.2998 - val_sparse_categorical_accuracy: 0.8889\n",
            "Epoch 3/20\n",
            "1500/1500 [==============================] - 41s 27ms/step - loss: 0.3534 - sparse_categorical_accuracy: 0.8757 - val_loss: 0.2589 - val_sparse_categorical_accuracy: 0.9076\n",
            "Epoch 4/20\n",
            "1500/1500 [==============================] - 42s 28ms/step - loss: 0.3133 - sparse_categorical_accuracy: 0.8864 - val_loss: 0.2436 - val_sparse_categorical_accuracy: 0.9129\n",
            "Epoch 5/20\n",
            "1500/1500 [==============================] - 41s 27ms/step - loss: 0.2870 - sparse_categorical_accuracy: 0.8976 - val_loss: 0.2363 - val_sparse_categorical_accuracy: 0.9141\n",
            "Epoch 6/20\n",
            "1500/1500 [==============================] - 44s 29ms/step - loss: 0.2647 - sparse_categorical_accuracy: 0.9040 - val_loss: 0.2210 - val_sparse_categorical_accuracy: 0.9203\n",
            "Epoch 7/20\n",
            "1500/1500 [==============================] - 42s 28ms/step - loss: 0.2513 - sparse_categorical_accuracy: 0.9074 - val_loss: 0.2237 - val_sparse_categorical_accuracy: 0.9184\n",
            "Epoch 8/20\n",
            "1500/1500 [==============================] - 41s 27ms/step - loss: 0.2360 - sparse_categorical_accuracy: 0.9133 - val_loss: 0.2273 - val_sparse_categorical_accuracy: 0.9158\n",
            "Epoch 9/20\n",
            "1500/1500 [==============================] - 41s 27ms/step - loss: 0.2233 - sparse_categorical_accuracy: 0.9172 - val_loss: 0.2118 - val_sparse_categorical_accuracy: 0.9233\n",
            "Epoch 10/20\n",
            "1500/1500 [==============================] - 41s 27ms/step - loss: 0.2103 - sparse_categorical_accuracy: 0.9234 - val_loss: 0.2229 - val_sparse_categorical_accuracy: 0.9194\n",
            "Epoch 11/20\n",
            "1500/1500 [==============================] - 42s 28ms/step - loss: 0.2033 - sparse_categorical_accuracy: 0.9237 - val_loss: 0.2146 - val_sparse_categorical_accuracy: 0.9252\n",
            "Epoch 12/20\n",
            "1500/1500 [==============================] - 41s 27ms/step - loss: 0.1923 - sparse_categorical_accuracy: 0.9269 - val_loss: 0.2111 - val_sparse_categorical_accuracy: 0.9273\n",
            "Epoch 13/20\n",
            "1500/1500 [==============================] - 41s 27ms/step - loss: 0.1856 - sparse_categorical_accuracy: 0.9312 - val_loss: 0.2209 - val_sparse_categorical_accuracy: 0.9227\n",
            "Epoch 14/20\n",
            "1500/1500 [==============================] - 41s 28ms/step - loss: 0.1772 - sparse_categorical_accuracy: 0.9348 - val_loss: 0.2358 - val_sparse_categorical_accuracy: 0.9195\n",
            "Epoch 15/20\n",
            "1500/1500 [==============================] - 41s 27ms/step - loss: 0.1716 - sparse_categorical_accuracy: 0.9358 - val_loss: 0.2165 - val_sparse_categorical_accuracy: 0.9263\n",
            "Epoch 15: early stopping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This relatively simple CNN appears to be todays winner, with a validation accuracy of 92.6%. "
      ],
      "metadata": {
        "id": "csUNiTrJaV6x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.figure()\n",
        "plt.plot(history7.history['sparse_categorical_accuracy'], label=\"Training loss\")\n",
        "plt.plot(history7.history['val_sparse_categorical_accuracy'], label=\"Validation loss\")\n",
        "plt.title(\"Model accuracy by epoch\")\n",
        "plt.legend()\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Accuracy\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "id": "cPhp8RVkaxKD",
        "outputId": "579d0b7a-1b91-4d0c-d258-e34018d6927d"
      },
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'Accuracy')"
            ]
          },
          "metadata": {},
          "execution_count": 137
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model 7 is not seriously overtrained, but it is definitely good that we stopped when we did.\n",
        "\n",
        " Let's test all these models, declaring in advance that Model 7 is my \"official\" model."
      ],
      "metadata": {
        "id": "SGWC2a40cUjQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "models = [\n",
        "    model0,\n",
        "    model1,\n",
        "    model2,\n",
        "    model3,\n",
        "    model4,\n",
        "    model5,\n",
        "    model6,\n",
        "    model7\n",
        "]\n",
        "loss = []\n",
        "accuracy = []\n",
        "for model in models:\n",
        "  v = model.evaluate(X_test_f, y_test_f)\n",
        "  loss.append(v[0])\n",
        "  accuracy.append(v[1])\n",
        "\n",
        "plt.figure(figsize=(10,4))\n",
        "plt.subplot(121)\n",
        "plt.bar(range(8), loss)\n",
        "plt.title(\"Test loss by model\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.xlabel(\"Model\")\n",
        "plt.subplot(122)\n",
        "plt.bar(range(8), accuracy)\n",
        "plt.title(\"Test accuracy by model\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.xlabel(\"Model\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 451
        },
        "id": "-qRWoWlvp28V",
        "outputId": "88f031f6-df04-4802-8120-fb0d4c578564"
      },
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 0s 1ms/step - loss: 0.4483 - sparse_categorical_accuracy: 0.8440\n",
            "313/313 [==============================] - 0s 1ms/step - loss: 0.3655 - sparse_categorical_accuracy: 0.8712\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.3772 - sparse_categorical_accuracy: 0.8719\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.3562 - sparse_categorical_accuracy: 0.8827\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.3048 - sparse_categorical_accuracy: 0.9115\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.2660 - sparse_categorical_accuracy: 0.9077\n",
            "313/313 [==============================] - 13s 40ms/step - loss: 0.5497 - sparse_categorical_accuracy: 0.8749\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 0.2437 - sparse_categorical_accuracy: 0.9182\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 0, 'Model')"
            ]
          },
          "metadata": {},
          "execution_count": 144
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Our official model, model 7, has the highest test accuracy! Its test accuracy of 91.8% beats out every other model. Model 4 likewise performed fairly well. Model 6, on the other hand, dramatically underperforms the other CNNs, especially with respect to test loss. It's worth investigating what caused that.\n",
        "\n",
        "Now let's implement Model 7 on MNIST quickly. It is well-established that MNIST is a fairly easy problem, so I expect good performance."
      ],
      "metadata": {
        "id": "NkRAqMmiDo2Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "d_model7 = tf.keras.Sequential([\n",
        "    layers.InputLayer(input_shape=(28,28,1)),\n",
        "    layers.Rescaling(1.0/255),\n",
        "    layers.Conv2D(32, kernel_size=(3,3), input_shape=(28,28,1), padding='same', activation='relu'),\n",
        "    layers.MaxPool2D(pool_size=(2,2)),\n",
        "    layers.Conv2D(64, kernel_size=(3,3), padding='same', activation='relu'),\n",
        "    layers.MaxPool2D(pool_size=(2,2)),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(128, activation='relu'),\n",
        "    layers.Dropout(0.6),\n",
        "    layers.Dense(10)\n",
        "])\n",
        "d_model7.compile(optimizer=tf.keras.optimizers.Adam(0.001),\n",
        "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])\n"
      ],
      "metadata": {
        "id": "8g1x2GYFEjsX"
      },
      "execution_count": 145,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "d_history7 = d_model7.fit(X_train_d, y_train_d, epochs=20,\n",
        "                      validation_data=(X_val_d, y_val_d), callbacks=[callback])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n84-FKm7E5eF",
        "outputId": "c212aa68-998f-4d60-b2f8-177dd47bf292"
      },
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "1500/1500 [==============================] - 42s 28ms/step - loss: 0.2752 - sparse_categorical_accuracy: 0.9150 - val_loss: 0.0675 - val_sparse_categorical_accuracy: 0.9803\n",
            "Epoch 2/20\n",
            "1500/1500 [==============================] - 43s 29ms/step - loss: 0.1106 - sparse_categorical_accuracy: 0.9674 - val_loss: 0.0467 - val_sparse_categorical_accuracy: 0.9868\n",
            "Epoch 3/20\n",
            "1500/1500 [==============================] - 40s 27ms/step - loss: 0.0800 - sparse_categorical_accuracy: 0.9762 - val_loss: 0.0422 - val_sparse_categorical_accuracy: 0.9880\n",
            "Epoch 4/20\n",
            "1500/1500 [==============================] - 40s 27ms/step - loss: 0.0643 - sparse_categorical_accuracy: 0.9803 - val_loss: 0.0424 - val_sparse_categorical_accuracy: 0.9887\n",
            "Epoch 5/20\n",
            "1500/1500 [==============================] - 41s 28ms/step - loss: 0.0549 - sparse_categorical_accuracy: 0.9833 - val_loss: 0.0400 - val_sparse_categorical_accuracy: 0.9892\n",
            "Epoch 6/20\n",
            "1500/1500 [==============================] - 40s 27ms/step - loss: 0.0470 - sparse_categorical_accuracy: 0.9858 - val_loss: 0.0439 - val_sparse_categorical_accuracy: 0.9888\n",
            "Epoch 7/20\n",
            "1500/1500 [==============================] - 40s 27ms/step - loss: 0.0419 - sparse_categorical_accuracy: 0.9869 - val_loss: 0.0425 - val_sparse_categorical_accuracy: 0.9883\n",
            "Epoch 8/20\n",
            "1500/1500 [==============================] - 41s 27ms/step - loss: 0.0378 - sparse_categorical_accuracy: 0.9879 - val_loss: 0.0382 - val_sparse_categorical_accuracy: 0.9902\n",
            "Epoch 9/20\n",
            "1500/1500 [==============================] - 40s 27ms/step - loss: 0.0340 - sparse_categorical_accuracy: 0.9892 - val_loss: 0.0384 - val_sparse_categorical_accuracy: 0.9909\n",
            "Epoch 10/20\n",
            "1500/1500 [==============================] - 41s 27ms/step - loss: 0.0296 - sparse_categorical_accuracy: 0.9907 - val_loss: 0.0391 - val_sparse_categorical_accuracy: 0.9895\n",
            "Epoch 11/20\n",
            "1500/1500 [==============================] - 40s 27ms/step - loss: 0.0275 - sparse_categorical_accuracy: 0.9914 - val_loss: 0.0408 - val_sparse_categorical_accuracy: 0.9903\n",
            "Epoch 11: early stopping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "d_model7.evaluate(X_test_d, y_test_d)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xBu3VQeYG6ac",
        "outputId": "01795981-2188-4668-ecc1-724d24057191"
      },
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 3s 8ms/step - loss: 0.0278 - sparse_categorical_accuracy: 0.9923\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.02784891426563263, 0.9922999739646912]"
            ]
          },
          "metadata": {},
          "execution_count": 147
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "99.2% accuracy for the same model on MNIST! Now let's save the good models."
      ],
      "metadata": {
        "id": "zfmmgOSVHGnk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model7.save(\"trained_FMNIST_model\")"
      ],
      "metadata": {
        "id": "kHU8takvHOQ_"
      },
      "execution_count": 148,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "d_model7.save(\"trained_MNIST_model\")"
      ],
      "metadata": {
        "id": "-Jx_mKyeH2y_"
      },
      "execution_count": 149,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": [],
      "authorship_tag": "ABX9TyOCby7L6ZnlP4ndwDYnduqu"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}